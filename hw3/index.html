<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 3 Write-Up</h1>
		<div style="text-align: center;">Names: Yongye Zhu, Shashank Anand</div>

		<br>

		Link to webpage: <a href="https://github.com/cal-cs184-student/sp25-hw3-fpsg-hw3">https://github.com/cal-cs184-student/sp25-hw3-fpsg-hw3</a>
		<br>
		Link to GitHub repository: <a href="https://github.com/cal-cs184-student/hw-webpages-fpsg-webpage">https://github.com/cal-cs184-student/hw-webpages-fpsg-webpage</a>
		
		<!-- <figure>
			<img src="cornell.png" alt="Cornell Boxes with Bunnies" style="width:70%"/>
			<figcaption>You can add images with captions!</figcaption>
		</figure> -->

		<!--
		We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		In this homework, we mainly work on implementing efficient ray tracing algorithms. In order to accomplish this, we first build ray objects shot from the camera and implement ray-sphere and ray-triangle intersection. We then accelerate ray-object intersection by building a bounded box hierarchy. After that, we implement direct illumination by random sampling points on the hemisphere on ray-object intersections and optimize the radiance calculation by importance sampling. Then we implement indirect illumination by accumulating direct illumination with rays bounding from surfaces other than the light source. We use Russian roulette termination to terminate the bouncing lights. At the very end, we use adaptive sampling to sample more on points that are hard to converge. 
		<br>
		<br>
		Throughout the homework, the most important thing is to figure out what coordinate the vector lives in and do the proper transformation on that. Accumulating the correct numerical value when calculating the illumination is also important. 

		<h2>Part 1: Ray Generation and Scene Intersection</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		<p>Here is an example 2x2 gridlike structure using an HTML table. Each <b>tr</b> is a row and each <b>td</b> is a column in that row. You might find this useful for framing and showing your result images in an organized fashion.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="cornell.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="cornell.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="cornell.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="cornell.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		
		<h2>Part 2: Bounding Volume Hierarchy</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		<h2>Part 3: Direct Illumination</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		<h2>Part 4: Global Illumination</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		<h2>Part 5: Adaptive Sampling</h2>
		Adaptive sampling attempts to generate noise free images by distributing samples over pixels depending on their convergence rate. We use more samples for difficult regions and fewer samples for "easier" regions.
		In our implementation, we modify the raytrace_pixel function. Inside the sampling loop for each pixel, we add a termination check. This termination check is triggered every samplesPerBatch pixels, and terminates out of the loop early if the desired convergence rate has been achieved. We check for convergence using the described method in the Part 5 page: using the variance of samples so far and checking that \(1.96*\sqrt{\frac{\sigma}{n}} \leq maxTolerance*\mu\). When terminating early, we use the value of i as number of samples evaluated.
		
		We render 2048 samples of the bunny model and the wall-e model with the following commands:<br/>
		<code> ./pathtracer -t 8 -s 2048 -a 64 0.05 -l 1 -m 5 -r 480 360 -f bunny.png ../dae/sky/CBbunny.dae </code> <br/>

		<code> ./pathtracer -t 8 -s 2048 -a 64 0.05 -l 1 -m 5 -r 480 360 -f wall-e.png ../dae/sky/wall-e.dae </code> <br/>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="figs/part5/bunny.png" width="400px"/>
				  <figcaption>Bunny with 2048 samples</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="figs/part5/bunny_rate.png" width="400px"/>
				  <figcaption>Bunny sample heatmap</figcaption>
				</td>
			  </tr>
			  <tr></tr>
				<td style="text-align: center;">
				  <img src="figs/part5/wall-e.png" width="400px"/>
				  <figcaption>Wall-E with 2048 samples</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="figs/part5/wall-e_rate.png" width="400px"/>
				  <figcaption>Wall-E sample heatmap</figcaption>
				</td>
			  </tr>
			</table>

		<h2>(Optional) Part 6: Extra Credit Opportunities</h2>
		<h3> Extra Credit 1: Better BVH splitting using surface area heuristic</h3>
			To improve performance, we implemented a better BVH splitting algorithm using the surface area heuristic.
			For each axis, we evaluate the best partition among all the primitives by iterating through the sorted list of primitives and calculating the cost of splitting at each primitive. The cost of splitting is equal to the cost of intersecting the left and right boxes. The cost of intersecting a box is equal to the probability of intersecting this box (proportional to the surface area) times the number of primitives in this box.
			We minimize this cost for each axis, and pick the best cost among all three axes.
			We skip straight to path tracing the 2048 sample bunny from Part 5:
			<code> ./pathtracer -t 8 -s 2048 -a 64 0.05 -l 1 -m 5 -r 480 360 -f bunny.png ../dae/sky/CBbunny.dae </code>
			We see a significant speedup in rendering time, going from 237 seconds without SAH splitting, to 154 seconds with SAH splitting, an approximately 35% improvement.
		
		<h3> Extra Credit 2 + 3: Optimizations </h3>
			We perform the following optimizations: Replace recursion with stack traversal in bbox construction, z culling when sampling lights, and more optimized bbox and bvh tests. We mention them as 2 extra credits as they are two separate items in the extra credit list.
			As above, we run the 2048 sample bunny from Part 5. We get a good spedup, rendering time going from 154 seconds with SAH splitting to 130 seconds with SAH splitting and optimizations, an approximately 15% improvement.

		<h3> Extra Credit 4: Jittered Sampling </h3>
			We create a new class of 2D Sampler called the JitteredSampler2D. During instantiation, an NxN grid is created, and we randomly sample a point inside this grid and store it. When calling sample(), we uniformly randomly generate i,j between [0,1] and use \((floor(i*N), floor(j*N))\) as the grid to pick the sample point from.
			This provides us with a better distributed set of samples.

			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
				  <tr>
					<td style="text-align: center;">
					  <img src="figs/part6/bunny.png" width="400px"/>
					  <figcaption>Uniform random pixel sampling.</figcaption>
					</td>
					<td style="text-align: center;">
					  <img src="figs/part6/bunny_jit.png" width="400px"/>
					  <figcaption>Jittered sampling</figcaption>
					</td>
				  </tr>
				</table>
			</div>

			The difference in the pictures above are not very apparent, but we can see upon zooming in that jittered sampling provides better fidelity and less aliasing along the edges of the bunny. Particularly, the ears and the eyes show noticeable difference.
		</div>
	</body>
</html>